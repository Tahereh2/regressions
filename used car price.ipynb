{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398a5e7b",
   "metadata": {},
   "source": [
    "# used car price project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db11d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa4ab80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Body</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>EngineV</th>\n",
       "      <th>Engine Type</th>\n",
       "      <th>Registration</th>\n",
       "      <th>Year</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>1991</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>van</td>\n",
       "      <td>427</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>yes</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sprinter 212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>13300.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>358</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Gas</td>\n",
       "      <td>yes</td>\n",
       "      <td>2003</td>\n",
       "      <td>S 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>240</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2007</td>\n",
       "      <td>Q7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>18300.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>120</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>yes</td>\n",
       "      <td>2011</td>\n",
       "      <td>Rav 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand    Price       Body  Mileage  EngineV Engine Type  \\\n",
       "0            BMW   4200.0      sedan      277      2.0      Petrol   \n",
       "1  Mercedes-Benz   7900.0        van      427      2.9      Diesel   \n",
       "2  Mercedes-Benz  13300.0      sedan      358      5.0         Gas   \n",
       "3           Audi  23000.0  crossover      240      4.2      Petrol   \n",
       "4         Toyota  18300.0  crossover      120      2.0      Petrol   \n",
       "\n",
       "  Registration  Year         Model  \n",
       "0          yes  1991           320  \n",
       "1          yes  1999  Sprinter 212  \n",
       "2          yes  2003         S 500  \n",
       "3          yes  2007            Q7  \n",
       "4          yes  2011         Rav 4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the dataset\n",
    "raw_data=pd.read_csv(\"D:\\\\tala\\\\data science projects\\\\dr.fozouni\\\\Used Cars Price.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cf9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a458c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()\n",
    "#information about each columns (this dataset has totally 9 columns and 4345 rows or records) and we have to do preprocessing \n",
    "#data wrangling and data mining\n",
    "#data wrangling(discovery(clean , structure , orgnize , map) , transformat(structuring(join , union) , normalize , cleaning, enriching) , validation , publishing)\n",
    "#data mining(identify correlation , find patherns and variations , understand trends and predict probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa28d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe(include=\"all\")\n",
    "#descriptive statistic(central tendency(mean , mode , median) , dispersion(variance , standard devirtion , range) , skewness(symetric , right , left))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb086edd",
   "metadata": {},
   "source": [
    "preprocessing\n",
    "data wrangling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51f7ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#attribute Model has 312 types(unique=312) so as dummy variable we have to have 311 features in our modelof regression , so we delete this column by drop\n",
    "data=raw_data.drop([\"Model\"] , axis=1)\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44e1e9",
   "metadata": {},
   "source": [
    "# dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many missing value or null value do each columns have\n",
    "data.isnull().sum()\n",
    "#the result of isnull is boolian that means (True or False) by adding sum() we count how many of them for each column are null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the rows which have missing values\n",
    "data_no_mv=data.dropna(axis=0)\n",
    "data_no_mv.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34817a",
   "metadata": {},
   "source": [
    "dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the price column's datas\n",
    "sns.kdeplot(data_no_mv[\"Price\"] )#kernel dencity estimate\n",
    "#sns.distplot(data_no_mv[\"price\"]) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the price column's outliers\n",
    "q=data_no_mv[\"Price\"].quantile(0.98)\n",
    "data_1=data_no_mv[data_no_mv[\"Price\"]<q]\n",
    "data_1.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data_1[\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the mileage colum's datas\n",
    "sns.kdeplot(data_1[\"Mileage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the mileage column's outliers\n",
    "q=data_1[\"Mileage\"].quantile(0.99)\n",
    "data_2=data_1[data_1[\"Mileage\"]<q]\n",
    "data_2.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data_2[\"Mileage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the enginev column's datas\n",
    "sns.kdeplot(data_2[\"EngineV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=data_2[\"EngineV\"].quantile(0.993)\n",
    "data_3=data_2[data_2[\"EngineV\"]<q]\n",
    "data_3.describe(include=\"all\")\n",
    "#data_3=data_2[data_2[\"EngineV\"]<6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data_3[\"EngineV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the year column's datas\n",
    "sns.kdeplot(data_3[\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=data_3[\"Year\"].quantile(0.01)\n",
    "data_4=data_3[data_3[\"Year\"]>q]\n",
    "data_4.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26535b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data_4[\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e712fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec016c0",
   "metadata": {},
   "source": [
    "# reset the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# during the cleaning data index of row dont change due to deleting some od our rows we have to reset our indexes\n",
    "data_cleaned=data_4.reset_index()\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we dont need the ex indexes so we have to delet them\n",
    "data_cleaned=data_4.reset_index(drop=True)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf073cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistcs of cleaned data\n",
    "data_cleaned.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c79104",
   "metadata": {},
   "source": [
    "# data mining\n",
    "checking the regression assumption:\n",
    "1_linearity , 2_no endogeneity , 3_ normality and homoscedasticity , 4_no autocorrelation  , 5_no multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440ae1a",
   "metadata": {},
   "source": [
    "1_ linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943104e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linearity we only inspect numerical columns , categorical columns themself have thi lineaity\n",
    "#for drawing scatter plot we need matplotlib library\n",
    "fig , (ax1 , ax2 , ax3)=plt.subplots(1,3,sharey=False ,figsize=(15,3))# 1row and 3 columns\n",
    "\n",
    "ax1.scatter(data_cleaned[\"Year\"],data_cleaned[\"Price\"])\n",
    "ax1.set_title(\"price and year\")\n",
    "\n",
    "ax2.scatter(data_cleaned[\"EngineV\"],data_cleaned[\"Price\"])\n",
    "ax2.set_title(\"price and enginev\")\n",
    "\n",
    "ax3.scatter(data_cleaned[\"Mileage\"],data_cleaned[\"Price\"])\n",
    "ax3.set_title(\"price and mileage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43065e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use numpy library to log(we didnt have linearity)\n",
    "log_price=np.log(data_cleaned[\"Price\"])\n",
    "data_cleaned[\"log_price\"]=log_price\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , (ax1 , ax2 , ax3)=plt.subplots(1,3,sharey=False ,figsize=(15,3))# 1row and 3 columns\n",
    "\n",
    "ax1.scatter(data_cleaned[\"Year\"],data_cleaned[\"log_price\"])\n",
    "ax1.set_title(\"log_price and year\")\n",
    "\n",
    "ax2.scatter(data_cleaned[\"EngineV\"],data_cleaned[\"log_price\"])\n",
    "ax2.set_title(\"log_price and enginev\")\n",
    "\n",
    "ax3.scatter(data_cleaned[\"Mileage\"],data_cleaned[\"log_price\"])\n",
    "ax3.set_title(\"log_price and mileage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd657ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_2=data_cleaned.drop([\"Price\"] , axis=1)\n",
    "data_cleaned_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d8fc7",
   "metadata": {},
   "source": [
    "5_no multicollinearity\n",
    "VIF(variance inflation factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned_2.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c19d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import VIF from statsmodels library\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=data_cleaned_2[[\"Mileage\",\"Year\" , \"EngineV\"]]\n",
    "vif=pd.DataFrame()\n",
    "vif[\"VIF\"]=[variance_inflation_factor(variables.values , i) for i in range(variables.shape[1])]\n",
    "vif[\"features\"]=variables.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42420a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6125f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assumped=data_cleaned_2.drop([\"Year\"] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0888d6",
   "metadata": {},
   "source": [
    "# dummy  variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assumped.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2331421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to change categorical values to dummies (we cam use map too) by pandas\n",
    "#if we include a seperate dummy variable for each category , we will introduce mulyicollinearty to the regression\n",
    "data_with_dummies=pd.get_dummies(data_assumped , drop_first=True)\n",
    "data_with_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_dummies.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c206d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of columns in order of our desire\n",
    "new_columns=['log_price','Mileage', 'EngineV', 'Brand_BMW',\n",
    "       'Brand_Mercedes-Benz', 'Brand_Mitsubishi', 'Brand_Renault',\n",
    "       'Brand_Toyota', 'Brand_Volkswagen', 'Body_hatch', 'Body_other',\n",
    "       'Body_sedan', 'Body_vagon', 'Body_van', 'Engine Type_Gas',\n",
    "       'Engine Type_Other', 'Engine Type_Petrol', 'Registration_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed=data_with_dummies[new_columns]\n",
    "data_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136d46f",
   "metadata": {},
   "source": [
    "standardizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for standardizing our data we yse sklearn library\n",
    "#standardizing is subset of normalizing and it's subset of transformt (data wrangling)\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb82582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to standard only our inputs and dont need to standard our target\n",
    "inputs=data_preprocessed.drop([\"log_price\"] , axis=1)\n",
    "target=data_preprocessed[\"log_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "inputs_scaled=scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de88353",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eedad9a",
   "metadata": {},
   "source": [
    "# splitting our dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test , y_train , y_test=train_test_split(inputs_scaled , target , test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90916f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.shape  , x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c72b6",
   "metadata": {},
   "source": [
    "# making our regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=LinearRegression()\n",
    "reg.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat means predicting (y) not real ones\n",
    "y_hat=reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scotting difrence between real y and predicting ones\n",
    "plt.scatter(y_train , y_hat)\n",
    "\n",
    "plt.xlabel(\"real ones\" , size=15)\n",
    "plt.ylabel(\"prediction\" , size=15)\n",
    "\n",
    "plt.xlim(6,13)\n",
    "plt.ylim(6,13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error  is diffrence between the observed value and the true value\n",
    "#residual  is the diffrence between observed value and the predicted value(by the model)\n",
    "sns.kdeplot(y_train - y_hat )\n",
    "plt.title(\"residual\" , size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c84fe0",
   "metadata": {},
   "source": [
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45012b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d33b7",
   "metadata": {},
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68590337",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3c42e",
   "metadata": {},
   "source": [
    "coaffictiont(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3988a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights interpretation:  \n",
    "#countinuous variables (positive shows by inccreasin input our target increase and negetive means by increasing input our target decreas)\n",
    "#dummy variable(positive shows our category valuble more expensive than our benchmark that omitted)\n",
    "reg_summary=pd.DataFrame(inputs.columns.values , columns=[\"features\"])\n",
    "reg_summary[\"weights\"]=reg.coef_\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7763f",
   "metadata": {},
   "source": [
    "# testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2421bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test=reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test , y_hat_test)\n",
    "\n",
    "plt.xlabel(\"target of test\" , size=15)\n",
    "plt.ylabel(\"prediction of test\" , size=15)\n",
    "\n",
    "plt.xlim(6,14)\n",
    "plt.ylim(6,14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe and change target from log to ints normal size by exp in numpy\n",
    "df_performance=pd.DataFrame(np.exp(y_hat_test) , columns=[\"prediction\"])\n",
    "df_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b016a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we made dataframe by pandas and pandas is royalty to index so the target numbers becoms NaN\n",
    "df_performance[\"target\"]=np.exp(y_test)\n",
    "df_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to reset the index to omitt the Nan in targets\n",
    "y_test=y_test.reset_index(drop=True)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4082649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance[\"target\"]=np.exp(y_test)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b75bcc",
   "metadata": {},
   "source": [
    "# calculating percentage of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance[\"residual\"]=df_performance[\"target\"]-df_performance[\"prediction\"]\n",
    "df_performance[\"percent error\"]=np.absolute(df_performance[\"residual\"]/df_performance[\"target\"]*100)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0035fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describing the dataframe\n",
    "df_performance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c015ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fo more interpret we sort df ny percent error\n",
    "pd.options.display.max_rows=999 #y this code it present all  the dataset\n",
    "\n",
    "df_performance.sort_values(by=[\"percent error\"] , inplace=True)\n",
    "df_performance                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change the type of target to int\n",
    "df_performance[\"target\"]=df_performance[\"target\"].astype(int)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get a rounded two decimalfloat number\n",
    "pd.set_option(\"display.float_format\" , lambda x:\"%.2f\" %x)\n",
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8047ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can rounded the weights of our regression model\n",
    "np.round(reg_summary ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef5c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
